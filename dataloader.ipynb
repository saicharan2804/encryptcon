{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZwnvJjFAM4EXUTw8DA69u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saicharan2804/encryptcon/blob/main/dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from pdf2image import convert_from_path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "URuas8t0mTlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_csv(csv_path):\n",
        "    # Load CSV\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Drop specified columns\n",
        "    columns_to_drop = ['Unnamed: 0', 'ARB Project', 'State', 'Project Site Location',\n",
        "                       'Reversals Covered by Buffer Pool', 'Reversals Not Covered by Buffer']\n",
        "    df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "    # Merge specified columns into arrays\n",
        "    vintage_issue_cols = [str(year) for year in range(2009, 2024)]\n",
        "    retired_credits_cols = vintage_issue_cols.copy()  #change this line after reanming the columns\n",
        "\n",
        "    df['vintage_issue'] = df[vintage_issue_cols].values.tolist()\n",
        "    df['retired_credits'] = df[retired_credits_cols].values.tolist()\n",
        "\n",
        "    # Drop the original year columns\n",
        "    df.drop(columns=vintage_issue_cols + retired_credits_cols, inplace=True, errors='ignore')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "EVlHK5vt7A3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a PDF file to images\n",
        "def convert_pdf_to_images(pdf_path):\n",
        "    return convert_from_path(pdf_path)\n",
        "\n",
        "# Function to get concatenated representation of a document\n",
        "def get_concatenated_representation(pdf_path, processor, model):\n",
        "    image_array = convert_pdf_to_images(pdf_path)\n",
        "    concatenated_outputs = []\n",
        "    for image in image_array:\n",
        "        pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(model.device)\n",
        "        outputs = model.encoder(pixel_values)\n",
        "        concatenated_outputs.append(outputs.pooler_output)\n",
        "    return torch.cat(concatenated_outputs, dim=1)\n",
        "\n",
        "# Custom Dataset\n",
        "class PDFDocumentDataset(Dataset):\n",
        "    def __init__(self, csv_path, pdf_folder_path, processor, model):\n",
        "        self.dataframe = load_and_preprocess_csv(csv_path)\n",
        "        self.pdf_folder_path = pdf_folder_path\n",
        "        self.processor = processor\n",
        "        self.model = model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        pdf_path = f\"{self.pdf_folder_path}/{row['Project ID']}.pdf\"\n",
        "        embeddings = get_concatenated_representation(pdf_path, self.processor, self.model)\n",
        "\n",
        "        # Create a comma-separated text from the row, excluding embeddings-related data\n",
        "        text_data = row.drop(['Project ID', 'vintage_issue', 'retired_credits']).to_csv(header=False, index=False).strip('\\n')\n",
        "\n",
        "        # Prepare the output dictionary\n",
        "        return {\n",
        "            \"project_id\": row['Project ID'],\n",
        "            \"description\": text_data,\n",
        "            \"vintage_issue\": row['vintage_issue'],\n",
        "            \"retired_credits\": row['retired_credits'],\n",
        "            \"embeddings\": embeddings\n",
        "        }"
      ],
      "metadata": {
        "id": "NdWXUyuImUWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the processor and model\n",
        "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hRZ5FExVynTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of PDF file paths\n",
        "csv_path = 'path_to_csv_file.csv'\n",
        "pdd_folder_path = 'path_to_pdf_folder'"
      ],
      "metadata": {
        "id": "ydW64DgKypIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset and DataLoader\n",
        "dataset = PDFDocumentDataset(csv_path, pdd_folder_path, processor, model)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "fmJ5mBwPytuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over DataLoader\n",
        "for data in dataloader:\n",
        "    print(f\"Project ID: {data['project_id']}\")\n",
        "    print(f\"Description: {data['description']}\")\n",
        "    print(f\"Vintage Issue: {data['vintage_issue']}\")\n",
        "    print(f\"Retired Credits: {data['retired_credits']}\")\n",
        "    print(f\"Document Embeddings Shape: {data['embeddings'].shape}\")"
      ],
      "metadata": {
        "id": "qMErfrUqyw9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}